{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, I'll write some code to extract all instances of in situ questions from Sheet 1 of the `all_rows_classified.xls` file. My collegue Lena Baunaz will then classify them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1', 'Sheet2']\n",
      "['export_requete_corpus_22-08-202']\n",
      "['quand', 'Sheet1']\n",
      "['Sheet1', 'Sheet2']\n"
     ]
    }
   ],
   "source": [
    "# reads in the spreadsheet data\n",
    "\n",
    "workbook1 = xlrd.open_workbook('comment_all_rows_classified.xls')\n",
    "data1 = pd.ExcelFile(workbook1)\n",
    "\n",
    "workbook2 = xlrd.open_workbook('où_interrogatives_GLOBAL.xls')\n",
    "data2 = pd.ExcelFile(workbook2)\n",
    "\n",
    "workbook3 = xlrd.open_workbook('quand_interrogatives_GLOBAL.xls')\n",
    "data3 = pd.ExcelFile(workbook3)\n",
    "\n",
    "workbook4 = xlrd.open_workbook('qui_all_rows_classified.xls')\n",
    "data4 = pd.ExcelFile(workbook4)\n",
    "\n",
    " # returns the all the sheet names within the excel file\n",
    "print(data1.sheet_names)\n",
    "print(data2.sheet_names)\n",
    "print(data3.sheet_names)\n",
    "print(data4.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 1: 2103\n",
      "Total columns 1: 13\n",
      "Total rows 2: 868\n",
      "Total columns 1: 13\n",
      "Total rows 3: 357\n",
      "Total columns 1: 13\n",
      "Total rows 4: 780\n",
      "Total columns 1: 13\n"
     ]
    }
   ],
   "source": [
    "sheet1 = workbook1.sheet_by_name('Sheet1')\n",
    "sheet2 = workbook2.sheet_by_name('export_requete_corpus_22-08-202')\n",
    "sheet3 = workbook3.sheet_by_name('quand')\n",
    "sheet4 = workbook4.sheet_by_name('Sheet1')\n",
    "\n",
    "row_count1 = sheet1.nrows\n",
    "col_count1 = sheet1.ncols\n",
    "\n",
    "row_count2 = sheet2.nrows\n",
    "col_count2 = sheet2.ncols\n",
    "\n",
    "row_count3 = sheet3.nrows\n",
    "col_count3 = sheet3.ncols\n",
    "\n",
    "row_count4 = sheet4.nrows\n",
    "col_count4 = sheet4.ncols\n",
    "\n",
    "# prints metrics\n",
    "print(f'Total rows 1: {row_count1}\\nTotal columns 1: {col_count1}')\n",
    "print(f'Total rows 2: {row_count2}\\nTotal columns 1: {col_count2}')\n",
    "print(f'Total rows 3: {row_count3}\\nTotal columns 1: {col_count3}')\n",
    "print(f'Total rows 4: {row_count4}\\nTotal columns 1: {col_count4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We extracted 196 rows of in situ non-cleft questions.\n",
      "We extracted 6 rows of in situ cleft questions.\n",
      "The selected rows are stored in a list of lists.\n",
      "[['Mot exact', 'comment', 'in situ', 'cleft', 'mono', \"c'est comment ?\", 'ESLO1_ENT_045', 'ESLO1_ENT_045_C', 'OU', 4976030.0], ['Mot exact', 'comment', 'in situ', 'cleft', 'mono', \"c'est comment est-ce qu'on fait une omelette chez vous ?\", 'ESLO1_ENT_046', 'ESLO1_ENT_046_C', 'PB', 5110.0], ['Mot exact', 'comment', 'in situ', 'cleft', 'mono', \"c'est comment on peut dire ? la foire\", 'ESLO1_ENT_092', 'ESLO1_ENT_092_C', 'KP392', 4725934.0], ['Mot exact', 'comment', 'in situ', 'cleft', 'mono', \"c'est comment vous appelez ça ?\", 'ESLO1_ENT_093', 'ESLO1_ENT_093_C', 'KT385', 1637224.0], ['Mot exact', 'comment', 'in situ', 'cleft', 'bi', \"comment vous trouvez c'est comment vous ?\", 'ESLO2_ENT_1057', 'ESLO2_ENT_1057_C', 'ch_LA11', 3716136.0], ['Mot exact', 'comment', 'in situ', 'cleft', 'mono', \"alors c'est comment la préhistoire ?\", 'ESLO2_REPAS_1260', 'ESLO2_REPAS_1260_C', 'BV647', 1825366.0]]\n"
     ]
    }
   ],
   "source": [
    "# extracts the data from first file\n",
    "\n",
    "# initialises the list that will contain all selected rows\n",
    "selected_data1 = [] # everything that's not a fragment nor an interjection\n",
    "\n",
    "# iterates through the spreadsheet to extract the data we need\n",
    "for rx in range(sheet.nrows): # rx is an int, row is a list \n",
    "    row = sheet.row(rx)\n",
    "\n",
    "    classification = row[2] # index 2 is where text of interest is stored, returns a cell\n",
    "    text_string = classification.value # converts cell into str\n",
    "\n",
    "    interrogative = row[3]\n",
    "    interr_string = interrogative.value\n",
    "\n",
    "    # initialises list that will contain our data\n",
    "    # one list is created during each iteration\n",
    "    data_list = []\n",
    "    cleft_list = []\n",
    "\n",
    "    # creates list that stores selected rows\n",
    "    if text_string == 'in situ':\n",
    "        # excludes strings classified as clefts\n",
    "        if interr_string == 'SV':\n",
    "            data_list.append(row[0].value)\n",
    "            data_list.append(row[1].value)\n",
    "            data_list.append(row[2].value)\n",
    "            data_list.append(row[3].value)\n",
    "            data_list.append(row[4].value)\n",
    "            data_list.append(row[5].value)\n",
    "            data_list.append(row[6].value)\n",
    "            data_list.append(row[7].value)\n",
    "            data_list.append(row[8].value)\n",
    "            data_list.append(row[9].value)\n",
    "\n",
    "            selected_data.append(data_list)\n",
    "\n",
    "        elif interr_string == 'cleft': \n",
    "            cleft_list.append(row[0].value)\n",
    "            cleft_list.append(row[1].value)\n",
    "            cleft_list.append(row[2].value)\n",
    "            cleft_list.append(row[3].value)\n",
    "            cleft_list.append(row[4].value)\n",
    "            cleft_list.append(row[5].value)\n",
    "            cleft_list.append(row[6].value)\n",
    "            cleft_list.append(row[7].value)\n",
    "            cleft_list.append(row[8].value)\n",
    "            cleft_list.append(row[9].value)\n",
    "\n",
    "            selected_data_clefts.append(cleft_list)\n",
    "    \n",
    "# prints extracted rows\n",
    "print(f'We extracted {len(selected_data)} rows of in situ non-cleft questions.')\n",
    "print(f'We extracted {len(selected_data_clefts)} rows of in situ cleft questions.')\n",
    "print(f'The selected rows are stored in a list of lists.')\n",
    "\n",
    "# we are going to exclude these from our analysis for now\n",
    "print('The excluded occurrences are the following:')\n",
    "print(selected_data_clefts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary converted into excel...\n"
     ]
    }
   ],
   "source": [
    "# creates spreadsheet using each nested list as a row\n",
    "\n",
    "df = pd.DataFrame(data=selected_data) # only adds non-clefts to the new file\n",
    "\n",
    "# converts into excel\n",
    "df.to_excel(\"comment_insitu.xlsx\", index=False)\n",
    "\n",
    "print(\"Dictionary converted into excel...\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7b2d02c07dc615871e2bd1a1246b89714f2151eeb8e00fcd4ada13785228d85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
